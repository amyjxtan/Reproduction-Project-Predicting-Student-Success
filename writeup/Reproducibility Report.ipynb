{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df5888d8",
   "metadata": {},
   "source": [
    "# Reproducibility of Enhancement of E-Learning Student’s Performance Based on Ensemble Techniques by Abdulkream A. Alsulami, Abdullah S. AL-Malaise AL-Ghamdi, & Mahmoud Ragab (2023, Electronics)\n",
    "\n",
    "\n",
    "Author: Amy Tan (amyjxtan@gmail.com)\n",
    "\n",
    "Date: `r format(Sys.time(), '%B %d, %Y')`\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The original paper, [\"Enhancement of E-Learning Student’s Performance Based on Ensemble Techniques\"](https://github.com/ucsd-psych201a/alsulami2023/blob/main/original_paper/Enhancement_of_ELearning_Students_Performance_Based_on_Ensemble_Techniques.pdf), aimed to improve educational data mining, or EDM, specifically in regards to electronic learning (e-learning) since the COVID-19 pandemic saw a surge in E-learning programs. EDM involves developing methods to deal with the different types of data in educational systems to improve students’ learning outcomes. In particular, the researchers sought to predict student performance using decision trees, naive Bayes, and random forests, enhancing the accuracy further through bagging and boosting. Researchers ultimately concluded that most accurate model methods used decision trees, coupled with boosting, resulting in an accuracy of 0.77.\n",
    "\n",
    "In my project, I sought to reproduce their findings and their visualizations in Python. I anticipated the largest challenges to be implementing the various EDM techniques as I wasn't extremely well-versed in either of them. However, I was confident that the challenge would not prove too difficult, and would be an extremely valuable learning experience. I chose this particular paper to reproduce since it fit into my niche of interests. The work I hope to do in the future involves an intersection of education, cognitive science, and computational tools - this paper provided the opportunity to further my knowledge and skills in how computational tools can and are used to better our education system. My work is available in my [project repository](https://github.com/ucsd-psych201a/alsulami2023/tree/main).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88725180",
   "metadata": {},
   "source": [
    "## Design Overview \n",
    "\n",
    "The paper's design did not include any manipulation of variables, but the data set contains 17 columns (measures) for 480 students. The gathering of the dataset and the following models that were built using it did not involve a within-participants or between-particiapnts design - measures were not repeated. If the dataset had been aimed at examining, for example, a specific learning method's effects on academic success, it could have been done either between or within subjects. The authors did not mention anything about reducing demand characteristics and since the paper isn't specifically aimed at determining a casual relationship, there aren't any confounds. I argue that more information in the original paper could be given on how the data was collected and why they chose to measure the specific variables they did. Without additional information, we are forced to take the dataset at face value and it's difficult to critically examine the data set design choices. There are limits to the models and their generalizability - since the data they are using are do not include folks from Western countries, it's difficult to say that this model would be accurate when applied to a different data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433c4700",
   "metadata": {},
   "source": [
    "## Project Progress Check 1\n",
    "\n",
    "The outcome measure for the success or failure of this reproduction project is if, out of all the models and data mining techniques, a decision tree with boosting proves to have the highest accuracy (around 0.77. The goal of the original paper was not focused on a particular test or hypothesis, but rather examining which model could be most effectively used to predict student success; likewise, my project aims to assess if the model they found is, in fact, the most accurate. As mentioned in the Methods section below, the accuracy will be computed using the formula:\n",
    "\n",
    "$$Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}$$\n",
    "\n",
    "My coding progress is under the Results section: I have finished data preprocessing - I have cleaned the dataset to have consist column names and values, fixing inconsistent capitalization and punctuation. Additionally I have written the code to split my dataset into training and testing - 30% is training and 70% is testing currently. I'm in the process still of writing the code to create model to train and test these data on. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec564070",
   "metadata": {},
   "source": [
    "## Methods\n",
    "### Materials\n",
    "\n",
    "#### The Data/Sample\n",
    "\n",
    "The dataset used in this project (provided in the data folder in `xAPI-Edu-Data.csv`, and also available on [Kaggle](https://www.kaggle.com/datasets/aljarah/xAPI-Edu-Data)) is the exact one used in the original paper. It was \"obtained from the Kalboard 360 E-Learning system via the Experience API (XAPI). The data set in this study consists of 480 records with 17 attributes.\" All attributes are either integer or categorical and are generally categorized into three major attribute types: demographic, academic, and behavioral.\n",
    "\n",
    "### Procedure\n",
    "\n",
    "\"First, we collect the data set and prepare it to perform the study. Then, three traditional data mining methods will apply (decision tree (DT), naïve Bayes (NB), and random forest (RF)) to produce a performance model. In addition to the classifiers mentioned earlier, two ensemble methods are used to improve their performance. Boosting, as well as bagging, is applied to enhance the student prediction model’s success. Two and three methods were added to each ensemble technique using the voting process for a more accurate prediction. The model’s last phase will involve evaluating and discussing the results. The data were divided into training and test sets. Each prediction model’s performance was evaluated using K-fold cross-validation. When testing a model, this technique is used to solve the variance problem. In brief, k-fold cross-validation divides the training set into 10 folds. During training, 9 folds are applied before the final fold is tested. As an average of the different accuracies is taken, this better represents the model performance. The method was repeated ten times. All models were run with the WEKA software’s default parameters.\" My analysis differs in that the models will be built and run in Python.\n",
    "\n",
    "### Analysis Plan\n",
    "\n",
    "#### Data Cleaning\n",
    "\n",
    "\"As part of preprocessing, data cleaning is essential for removing irrelevant objects and missing values in the data collection. There are zero missing values in the data set.\" Though the authors do not specifically mention this, I cleaned the data set with specific regard to the `NationalITy`, `PlaceofBirth`, and `StageID` columns to ensure that column contents were consistent in their usage of capitalization and abbreviations (or lack thereof). I did not exclude any of the data from the provided data set.\n",
    "\n",
    "#### Features Selection\n",
    "\n",
    "\"Feature selection refers to selecting the relevant features of a dataset based on specific criteria from an original feature set. There are two types of data reduction methods: wrapper methods and filter methods. The filter method ranks the features using variable ranking methods, with the highly ranked features being selected and implemented into the learning algorithm. In this study, the information gain ranking filter and a correlation- ranking filter were used. At each decision tree node, and in order to select the test attribute, the information gain measure is taken into account. The information gain (IG) metric determines features with a large number of values. It is calculated with Equation (1).\n",
    "\n",
    "$$IG(T, a) = H(T) − H(T|a)   (1)$$\n",
    "\n",
    "where $T$ is a random variable and $H(T|a)$ is the entropy of $T$ given the value of attribute a.\n",
    "\n",
    "Correlation coefficients are applied to measure correlations among attributes and classes and inter-correlations between features. It is calculated with Equation (2).\n",
    "\n",
    "$$\\rho(X,Y) = \\frac{\\text{cov}(X,Y)}{\\sigma_X\\sigma_Y} = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^n (x_i - \\bar{x})^2}\\sqrt{\\sum_{i=1}^n (y_i - \\bar{y})^2}}$$\n",
    "\n",
    "where:\n",
    "\n",
    "-   $X$ and $Y$ are the two variables being correlated\n",
    "-   $n$ is the number of data points\n",
    "-   $x_i$ and $y_i$ are the values of $X$ and $Y$ for the data point\n",
    "-   $\\bar{x}$ and $\\bar{y}$ are the means of $X$ and $Y$\n",
    "-   $\\text{cov}(X,Y)$ is the covariance between $X$ and $Y$\"\n",
    "\n",
    "#### Data Mining Tool and Model Creation\n",
    "\n",
    "After the most relevant features were selected, I used these to create a decision tree (DT), naïve Bayes (NB), and random forest (RF) classifiers. However, as previously mentioned, my project will not use WEKA, but Python. I anticipated using [skit-learn](https://scikit-learn.org/stable/) to accomplish building and testing these models. Following that, I applied boosting and bagging to all the models to test potential improvements.\"\n",
    "\n",
    "#### Measurement Measures\n",
    "\n",
    "\"Different DM techniques were compared to determine which had higher prediction accuracy than others, and a decision was made based on that. The following common metrics can evaluate a study’s performance: accuracy, precision, recall, and F-Measure.\" Thus, my project also examined all four measurements of accuracy to see if I could reproduce a similar finding that **decision trees with boosting had the highest accuracy of 0.77**. The following includes how the authors calculated each of the following, for which I followed suit.\n",
    "\n",
    "##### Accuracy\n",
    "\n",
    "\"This represents the classifier’s accuracy and relates to the classifier’s capacity. The accuracy of a predictor relates to the way it accurately predicts the impact of a predicted fea- ture for new information. The percentage of correct predictions divided by the total number of predictions yields the accuracy. It is calculated with the following Equation (3):\n",
    "\n",
    "$$Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}$$\n",
    "\n",
    "where: \n",
    "- True positives ($TP$): cases that are predicted as yes. \n",
    "- True negatives ($TN$): cases that are predicted as no. \n",
    "- False positives ($FP$): cases that are predicted yes and are actually yes. \n",
    "- False negatives ($FN$): cases that are predicted as no but are actually yes.\n",
    "\n",
    "##### Precision\n",
    "\n",
    "Precision is calculated as the ratio of correctly classified positive predictions to total positive predictions, whether correctly or incorrectly classified. It is calculated with Equation (4).\n",
    "\n",
    "$$Precision = \\frac{TP}{TP + FP}$$\n",
    "\n",
    "##### Recall\n",
    "\n",
    "The recall is determined by calculating the proportion of correctly classified positive predictions to all positive predictions. It is calculated with Equation (5).\n",
    "\n",
    "$$Recall = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "##### F-Measure\n",
    "\n",
    "F-measure conveys both recall and precision in a single measure. It is calculated with Equation (6).\"\n",
    "\n",
    "$$ F1 − measure = (2 ∗ Recall ∗ Precision)/(Recall + Precision)$$\n",
    "\n",
    "### Differences from Original Study\n",
    "\n",
    "Again, a key difference between this reproducibility project and the original paper are the computational tools used. The original paper used WEKA to visualize and perform machine learning/ensemble methods, whereas my project will use Python. Current anticipated packages include [seaborn](https://seaborn.pydata.org/index.html) and [skit-learn](https://scikit-learn.org/stable/). Additionally, I plan to clean the data using [pandas](https://pandas.pydata.org/) to ensure that entries are consistent, but I do not anticipate any changes I made to make a difference in the findings.\n",
    "\n",
    "\n",
    "\n",
    "### Methods Addendum (Post Data Collection)\n",
    "\n",
    "You can comment this section out prior to final report with data collection.\n",
    "\n",
    "#### Actual Sample\n",
    "\n",
    "Sample size, demographics, data exclusions based on rules spelled out in analysis plan\n",
    "\n",
    "#### Differences from pre-data collection methods plan\n",
    "\n",
    "Any differences from what was described as the original plan, or “none”.\n",
    "\n",
    "## Results\n",
    "\n",
    "### Data preparation\n",
    "\n",
    "Data preparation following the analysis plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ad2bc704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Nationality</th>\n",
       "      <th>Placeofbirth</th>\n",
       "      <th>Stageid</th>\n",
       "      <th>Gradeid</th>\n",
       "      <th>Sectionid</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Semester</th>\n",
       "      <th>Relation</th>\n",
       "      <th>Raisedhands</th>\n",
       "      <th>Visitedresources</th>\n",
       "      <th>Announcementsview</th>\n",
       "      <th>Discussion</th>\n",
       "      <th>Parentansweringsurvey</th>\n",
       "      <th>Parentschoolsatisfaction</th>\n",
       "      <th>Studentabsencedays</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>Kuwait</td>\n",
       "      <td>Kuwait</td>\n",
       "      <td>lowerlevel</td>\n",
       "      <td>G-04</td>\n",
       "      <td>A</td>\n",
       "      <td>IT</td>\n",
       "      <td>F</td>\n",
       "      <td>Father</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Good</td>\n",
       "      <td>Under-7</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>Kuwait</td>\n",
       "      <td>Kuwait</td>\n",
       "      <td>lowerlevel</td>\n",
       "      <td>G-04</td>\n",
       "      <td>A</td>\n",
       "      <td>IT</td>\n",
       "      <td>F</td>\n",
       "      <td>Father</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Good</td>\n",
       "      <td>Under-7</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>Kuwait</td>\n",
       "      <td>Kuwait</td>\n",
       "      <td>lowerlevel</td>\n",
       "      <td>G-04</td>\n",
       "      <td>A</td>\n",
       "      <td>IT</td>\n",
       "      <td>F</td>\n",
       "      <td>Father</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>No</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Above-7</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>Kuwait</td>\n",
       "      <td>Kuwait</td>\n",
       "      <td>lowerlevel</td>\n",
       "      <td>G-04</td>\n",
       "      <td>A</td>\n",
       "      <td>IT</td>\n",
       "      <td>F</td>\n",
       "      <td>Father</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>No</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Above-7</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>Kuwait</td>\n",
       "      <td>Kuwait</td>\n",
       "      <td>lowerlevel</td>\n",
       "      <td>G-04</td>\n",
       "      <td>A</td>\n",
       "      <td>IT</td>\n",
       "      <td>F</td>\n",
       "      <td>Father</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>No</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Above-7</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gender Nationality Placeofbirth     Stageid Gradeid Sectionid Topic  \\\n",
       "0      M      Kuwait       Kuwait  lowerlevel    G-04         A    IT   \n",
       "1      M      Kuwait       Kuwait  lowerlevel    G-04         A    IT   \n",
       "2      M      Kuwait       Kuwait  lowerlevel    G-04         A    IT   \n",
       "3      M      Kuwait       Kuwait  lowerlevel    G-04         A    IT   \n",
       "4      M      Kuwait       Kuwait  lowerlevel    G-04         A    IT   \n",
       "\n",
       "  Semester Relation  Raisedhands  Visitedresources  Announcementsview  \\\n",
       "0        F   Father           15                16                  2   \n",
       "1        F   Father           20                20                  3   \n",
       "2        F   Father           10                 7                  0   \n",
       "3        F   Father           30                25                  5   \n",
       "4        F   Father           40                50                 12   \n",
       "\n",
       "   Discussion Parentansweringsurvey Parentschoolsatisfaction  \\\n",
       "0          20                   Yes                     Good   \n",
       "1          25                   Yes                     Good   \n",
       "2          30                    No                      Bad   \n",
       "3          35                    No                      Bad   \n",
       "4          50                    No                      Bad   \n",
       "\n",
       "  Studentabsencedays Class  \n",
       "0            Under-7     M  \n",
       "1            Under-7     M  \n",
       "2            Above-7     L  \n",
       "3            Above-7     L  \n",
       "4            Above-7     M  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Load Relevant Libraries and Functions\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, plot_tree, export_text\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, get_scorer_names, mean_squared_error, r2_score, mean_squared_error, roc_auc_score, ConfusionMatrixDisplay, accuracy_score\n",
    "\n",
    "\n",
    "#### Import data\n",
    "\n",
    "edu = pd.read_csv('../data/xAPI-Edu-Data.csv')\n",
    "\n",
    "#### Data exclusion / filtering - NA\n",
    "\n",
    "#### Prepare data for analysis - create columns etc.\n",
    "\n",
    "# Clean dataset column names \n",
    "edu.columns = edu.columns.str.title()\n",
    "\n",
    "# Clean Placeofbirth column to clean random capitalization\n",
    "edu[\"Placeofbirth\"] = edu[\"Placeofbirth\"].str.title()\n",
    "\n",
    "# Clean Stageid column to clean random capitalization\n",
    "edu[\"Stageid\"] = edu[\"Stageid\"].str.lower()\n",
    "\n",
    "# Create a function to turn KW abbrevations into Kuwait for entry consistency in Nationality column\n",
    "def kuwait (string):\n",
    "    if string == 'KW':\n",
    "        return 'Kuwait'\n",
    "    else:\n",
    "        return string \n",
    "    \n",
    "# Apply function kuwait to Nationality column\n",
    "edu['Nationality'] = edu['Nationality'].apply(kuwait)\n",
    "\n",
    "# Double check that all cleaning was correct:\n",
    "edu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341eee5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_dummy(string):\n",
    "    for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0764fb2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raisedhands</th>\n",
       "      <th>Visitedresources</th>\n",
       "      <th>Announcementsview</th>\n",
       "      <th>Discussion</th>\n",
       "      <th>Gender_F</th>\n",
       "      <th>Gender_M</th>\n",
       "      <th>Nationality_Egypt</th>\n",
       "      <th>Nationality_Iran</th>\n",
       "      <th>Nationality_Iraq</th>\n",
       "      <th>Nationality_Jordan</th>\n",
       "      <th>...</th>\n",
       "      <th>Relation_Mum</th>\n",
       "      <th>Parentansweringsurvey_No</th>\n",
       "      <th>Parentansweringsurvey_Yes</th>\n",
       "      <th>Parentschoolsatisfaction_Bad</th>\n",
       "      <th>Parentschoolsatisfaction_Good</th>\n",
       "      <th>Studentabsencedays_Above-7</th>\n",
       "      <th>Studentabsencedays_Under-7</th>\n",
       "      <th>Class_H</th>\n",
       "      <th>Class_L</th>\n",
       "      <th>Class_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>50</td>\n",
       "      <td>77</td>\n",
       "      <td>14</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>55</td>\n",
       "      <td>74</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>35</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Raisedhands  Visitedresources  Announcementsview  Discussion  Gender_F  \\\n",
       "0             15                16                  2          20         0   \n",
       "1             20                20                  3          25         0   \n",
       "2             10                 7                  0          30         0   \n",
       "3             30                25                  5          35         0   \n",
       "4             40                50                 12          50         0   \n",
       "..           ...               ...                ...         ...       ...   \n",
       "475            5                 4                  5           8         1   \n",
       "476           50                77                 14          28         1   \n",
       "477           55                74                 25          29         1   \n",
       "478           30                17                 14          57         1   \n",
       "479           35                14                 23          62         1   \n",
       "\n",
       "     Gender_M  Nationality_Egypt  Nationality_Iran  Nationality_Iraq  \\\n",
       "0           1                  0                 0                 0   \n",
       "1           1                  0                 0                 0   \n",
       "2           1                  0                 0                 0   \n",
       "3           1                  0                 0                 0   \n",
       "4           1                  0                 0                 0   \n",
       "..        ...                ...               ...               ...   \n",
       "475         0                  0                 0                 0   \n",
       "476         0                  0                 0                 0   \n",
       "477         0                  0                 0                 0   \n",
       "478         0                  0                 0                 0   \n",
       "479         0                  0                 0                 0   \n",
       "\n",
       "     Nationality_Jordan  ...  Relation_Mum  Parentansweringsurvey_No  \\\n",
       "0                     0  ...             0                         0   \n",
       "1                     0  ...             0                         0   \n",
       "2                     0  ...             0                         1   \n",
       "3                     0  ...             0                         1   \n",
       "4                     0  ...             0                         1   \n",
       "..                  ...  ...           ...                       ...   \n",
       "475                   1  ...             0                         1   \n",
       "476                   1  ...             0                         1   \n",
       "477                   1  ...             0                         1   \n",
       "478                   1  ...             0                         1   \n",
       "479                   1  ...             0                         1   \n",
       "\n",
       "     Parentansweringsurvey_Yes  Parentschoolsatisfaction_Bad  \\\n",
       "0                            1                             0   \n",
       "1                            1                             0   \n",
       "2                            0                             1   \n",
       "3                            0                             1   \n",
       "4                            0                             1   \n",
       "..                         ...                           ...   \n",
       "475                          0                             1   \n",
       "476                          0                             1   \n",
       "477                          0                             1   \n",
       "478                          0                             1   \n",
       "479                          0                             1   \n",
       "\n",
       "     Parentschoolsatisfaction_Good  Studentabsencedays_Above-7  \\\n",
       "0                                1                           0   \n",
       "1                                1                           0   \n",
       "2                                0                           1   \n",
       "3                                0                           1   \n",
       "4                                0                           1   \n",
       "..                             ...                         ...   \n",
       "475                              0                           1   \n",
       "476                              0                           0   \n",
       "477                              0                           0   \n",
       "478                              0                           1   \n",
       "479                              0                           1   \n",
       "\n",
       "     Studentabsencedays_Under-7  Class_H  Class_L  Class_M  \n",
       "0                             1        0        0        1  \n",
       "1                             1        0        0        1  \n",
       "2                             0        0        1        0  \n",
       "3                             0        0        1        0  \n",
       "4                             0        0        0        1  \n",
       "..                          ...      ...      ...      ...  \n",
       "475                           0        0        1        0  \n",
       "476                           1        0        0        1  \n",
       "477                           1        0        0        1  \n",
       "478                           0        0        1        0  \n",
       "479                           0        0        1        0  \n",
       "\n",
       "[480 rows x 75 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edu_dummy = pd.get_dummies(edu).astype(int)\n",
    "edu_dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c005ceb5",
   "metadata": {},
   "source": [
    "\n",
    "### Confirmatory analysis\n",
    "\n",
    "The analyses as specified in the analysis plan.\n",
    "\n",
    "*Side-by-side graph with original graph is ideal here*\n",
    "\n",
    "#### Decision Tree\n",
    "Note, the original authors did not specify how they split their data into training vs. testing. In this instance, I am using a 30% testing and 70% training split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "907d33da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Y as what we're trying to classify\n",
    "Y = edu['Class']\n",
    "\n",
    "# Define X as our predictors (all columns besides 'Class')\n",
    "X = edu.drop('Class',axis=1)\n",
    "\n",
    "# Split data into training and testing \n",
    "X_train, X_test, Y_train, y_test = train_test_split(X, Y, test_size = 0.3, stratify = Y, random_state = 12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "114284b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'M'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/lp/wvqcc0x13jjb99jsy0mqncqr0000gn/T/ipykernel_18554/262643046.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Decision Tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Fit Decision Tree to training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Predict test set labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                 skip_parameter_validation=(\n\u001b[1;32m   1148\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m                 )\n\u001b[1;32m   1150\u001b[0m             ):\n\u001b[0;32m-> 1151\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    955\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m         \"\"\"\n\u001b[1;32m    958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m         super()._fit(\n\u001b[0m\u001b[1;32m    960\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    238\u001b[0m             check_X_params = dict(\n\u001b[1;32m    239\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             )\n\u001b[1;32m    241\u001b[0m             \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m             X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    243\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_separately\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             )\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    612\u001b[0m                 \u001b[0;31m# :(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m                 \u001b[0mcheck_X_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_separately\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"estimator\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheck_X_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m                     \u001b[0mcheck_X_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"estimator\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m                     \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    914\u001b[0m                         )\n\u001b[1;32m    915\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m                 raise ValueError(\n\u001b[1;32m    920\u001b[0m                     \u001b[0;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m                 ) from complex_warning\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1996\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1998\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1999\u001b[0m         if (\n\u001b[1;32m   2000\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2001\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'M'"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier(max_depth = 5)\n",
    "\n",
    "# Fit Decision Tree to training data\n",
    "dt.fit(X_train, Y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "Y_pred = dt.predict(X_test)\n",
    "\n",
    "# Compute test set accuracy\n",
    "print(confusion_matrix(y_pred, y_test))\n",
    "print(classification_report(y_pred, y_test))\n",
    "\n",
    "# Confusion Matrix\n",
    "ConfusionMatrixDisplay.from_estimator(dt, X_test, Y_test,\n",
    "        cmap = plt.cm.Blues, normalize = 'true')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c4dab3",
   "metadata": {},
   "source": [
    "\n",
    "### Exploratory analyses\n",
    "\n",
    "Any follow-up analyses desired (not required).\n",
    "\n",
    "## Discussion\n",
    "\n",
    "### Summary of Replication Attempt\n",
    "\n",
    "Open the discussion section with a paragraph summarizing the primary result from the confirmatory analysis and the assessment of whether it replicated, partially replicated, or failed to replicate the original result.\n",
    "\n",
    "### Commentary\n",
    "\n",
    "Add open-ended commentary (if any) reflecting (a) insights from follow-up exploratory analysis, (b) assessment of the meaning of the replication (or not) - e.g., for a failure to replicate, are the differences between original and present study ones that definitely, plausibly, or are unlikely to have been moderators of the result, and (c) discussion of any objections or challenges raised by the current and original authors about the replication attempt. None of these need to be long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580e22c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
